{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src import util as u\n",
    "\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import operator\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_csv(u.fn_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import author data with dates\n",
    "start = 1758\n",
    "end = 2018\n",
    "years = end-start\n",
    "timepoints = 4\n",
    "interval = round(years/3, 0)\n",
    "year1= start + interval*1\n",
    "year2= start + interval*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1758 1845.0\n",
      "1845.0 1932.0\n",
      "1932.0 2018\n"
     ]
    }
   ],
   "source": [
    "print(start, year1)\n",
    "print(year1, year2) # postal mail invented\n",
    "print(year2, end)   # airlines invested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejysoh/miniconda3/envs/msc/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "auth = pd.read_csv(u.fn_auth)[['idxes', 'full.name.of.describer.n', 'date.n']]\n",
    "\n",
    "auth1 = auth[(auth['date.n'] >= start) & (auth['date.n']  < year1)][['idxes', 'full.name.of.describer.n']]\n",
    "auth2 = auth[(auth['date.n'] >= year1) & (auth['date.n']  < year2)][['idxes', 'full.name.of.describer.n']]\n",
    "auth3 = auth[(auth['date.n'] >= year2) & (auth['date.n']  <= end)][['idxes', 'full.name.of.describer.n']]\n",
    "\n",
    "df_li =  [auth1, auth2, auth3]\n",
    "df_li = [x.groupby('idxes')['full.name.of.describer.n'].apply(lambda x: \"%s\" % '; '.join(x)) for x in df_li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pairs\n",
    "\n",
    "def li_pairs(source):\n",
    "    source = str.split(source, \"; \")\n",
    "    result = []\n",
    "    N = len(source)\n",
    "    if (N <= 1):\n",
    "        return [(source[0], None)]\n",
    "    else:\n",
    "\n",
    "        for p1 in range(N):\n",
    "            for p2 in range(p1+1,len(source)):\n",
    "                    result.append((source[p1],source[p2]))\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Philip Hunter Timberlake\n",
      "[('Philip Hunter Timberlake', None)]\n",
      "[('Osamu Tadauchi', 'Takeshi Matsumura')]\n"
     ]
    }
   ],
   "source": [
    "print(df_li[2].iloc[2])\n",
    "print(li_pairs(df_li[2].iloc[2]))\n",
    "print(li_pairs(df_li[2].iloc[63]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_li = [x.apply(lambda x: li_pairs(x)) for x in df_li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [[] for i in range(3)]\n",
    "for i in range(len(df_li)):\n",
    "    df = df_li[i]\n",
    "    for j, row in df.iteritems():\n",
    "        li[i].append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_li = [pd.DataFrame(x, columns=['p1', 'p2']) for x in li]\n",
    "df_li = [pd.DataFrame(x).groupby(['p1', 'p2']).size() for x in df_li]\n",
    "df_li = [x.reset_index() for x in df_li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges(df):\n",
    "    edges = []\n",
    "    for i, row in df.iterrows():\n",
    "        edges.append((row.p1, row.p2, row[0]))\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_li = [get_edges(df) for df in df_li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_names(edges):\n",
    "    all_node_names = []\n",
    "    all_node_names = [all_node_names + [e[0], e[1]] for e in edges]\n",
    "    all_node_names = reduce(operator.add, all_node_names)\n",
    "    return set(all_node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_names = [get_node_names(df) for df in df_li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into graph\n",
    "g_li = [nx.Graph() for x in range(3)]\n",
    "for i in range(len(df_li)):\n",
    "\n",
    "    g_li[i].add_nodes_from(node_names[i])\n",
    "    g_li[i].add_weighted_edges_from(df_li[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network 0\n",
      "Network density: 33.3 %\n",
      "Triadic closure: 0 %\n",
      "Number of subgraphs: 2\n",
      "Network diameter of largest component: 1\n",
      "\n",
      "\n",
      "Network 1\n",
      "Network density: 4.6 %\n",
      "Triadic closure: 0 %\n",
      "Number of subgraphs: 9\n",
      "Network diameter of largest component: 3\n",
      "\n",
      "\n",
      "Network 2\n",
      "Network density: 0.7 %\n",
      "Triadic closure: 5.9 %\n",
      "Number of subgraphs: 37\n",
      "Network diameter of largest component: 11\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_li)):\n",
    "    print(\"Network\", i)\n",
    "    \n",
    "    density = nx.density(g_li[i])\n",
    "    print(\"Network density:\", round(density*100, 1), \"%\")\n",
    "    \n",
    "    triadic_closure = nx.transitivity(g_li[i])\n",
    "    print(\"Triadic closure:\", round(triadic_closure*100, 1), \"%\")\n",
    "    \n",
    "    # Get subgraphs\n",
    "    subgraphs = [c for c in sorted(nx.connected_components(g_li[i]), key=len, reverse=True)]\n",
    "    print(\"Number of subgraphs:\", len(subgraphs))\n",
    "    \n",
    "    # Largest component\n",
    "    components = nx.connected_components(g_li[i])\n",
    "    largest_component = max(components, key=len) # max number of nodes\n",
    "\n",
    "    # Create a \"subgraph\" of just the largest component\n",
    "    # Then calculate the diameter of the subgraph, just like you did with density.\n",
    "    subgraph = g_li[i].subgraph(largest_component)\n",
    "    diameter = nx.diameter(subgraph)\n",
    "    print(\"Network diameter of largest component:\", diameter)\n",
    "    \n",
    "    \n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc",
   "language": "python",
   "name": "msc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

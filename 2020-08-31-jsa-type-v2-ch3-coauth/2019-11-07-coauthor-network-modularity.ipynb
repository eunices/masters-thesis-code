{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network analysis for coauthors - modularity\n",
    "\n",
    "This looks at modularity of the main subgraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.util import load_coauthor_nx, ddir, fn_nodes, fn_statoids, fn_spp\n",
    "\n",
    "import community\n",
    "import networkx as nx\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import skbio.diversity.alpha as b\n",
    "import math\n",
    "import random\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N nodes 389 ; N not nodes: 353\n",
      "Proportion who did not coauthor 47.6 %\n",
      "\n",
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 389\n",
      "Number of edges: 508\n",
      "Average degree:   2.6118\n"
     ]
    }
   ],
   "source": [
    "# Params\n",
    "seed = 2021\n",
    "random.seed(seed)\n",
    "\n",
    "# Load graph\n",
    "(G, nodes) = load_coauthor_nx() # abstracted into src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejysoh/miniconda3/envs/msc/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (22,30,60,61,65,86,89,106,117) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "nodes_df = pd.read_csv(fn_nodes)\n",
    "statoids = pd.read_csv(fn_statoids)\n",
    "statoids = area_dict = dict(zip(statoids.DL, statoids.Country))\n",
    "\n",
    "spp = pd.read_csv(fn_spp)[[\"idx\", \"full.name.of.describer\"]]\n",
    "spp = spp[spp.duplicated(subset=\"idx\", keep=False)]             # keep only those with >1 authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add module information\n",
    "communities = community.best_partition(G, random_state=seed)  # https://python-louvain.readthedocs.io/en/latest/api.html\n",
    "nx.set_node_attributes(G, communities, 'modularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country_of_residence': 'US',\n",
       " 'ns_spp_n': 224,\n",
       " 'degree': 31,\n",
       " 'betweenness': 0.15994704769615287,\n",
       " 'eigenvector': 0.45957800061955284,\n",
       " 'modularity': 8}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.nodes[\"Michael Scott Engel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get highest eigenvector centrality from each module\n",
    "# module_number refers to the original module number\n",
    "def get_highest_eigen_in_module(module_number):\n",
    "\n",
    "    module = [n for n in G.nodes() if G.nodes[n]['modularity'] == module_number]\n",
    "\n",
    "    print(\"Number of nodes: \", len(set(module)), \" in module \", module_number, \"\\n\")\n",
    "\n",
    "    # Then create a dictionary of the eigenvector centralities of those nodes\n",
    "    module_eigenvector = {n:G.nodes[n]['eigenvector'] for n in module}\n",
    "\n",
    "    # Then sort that dictionary and print the first 5 results\n",
    "    module_sorted_by_eigenvector = sorted(module_eigenvector.items(), key=itemgetter(1), reverse=True)\n",
    "    print(\"Modularity Sorted by Eigenvector Centrality:\")\n",
    "    for node in module_sorted_by_eigenvector[:10]:\n",
    "        print(node[0], \"| \", node[1], \" | \", G.nodes[node[0]]['country_of_residence'])\n",
    "        \n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes:  15  in module  0 \n",
      "\n",
      "Modularity Sorted by Eigenvector Centrality:\n",
      "Maximilian Schwarz |  0.08100179656093956  |  AU\n",
      "Fritz Josef [Friedrich] Gusenleitner |  0.01636534386715893  |  AU\n",
      "Karl Mazzucco |  0.012042369408000292  |  AU\n",
      "Esther Ockermüller |  0.011238094664371935  |  AU\n",
      "Jan Smit |  0.011238094664371935  |  NL\n",
      "Klaus Standfuss |  0.009868848295510732  |  GA\n",
      "Timofey Victorovich Levchenko |  0.009868848295510732  |  RS\n",
      "Erwin Scheuchl |  0.006731571119070798  |  GM\n",
      "Ardeshir Ariana |  0.0062603273188799125  |  JA\n",
      "Gerald Hölzler |  0.00146737440266006  |  AU\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the function on module 0\n",
    "get_highest_eigen_in_module(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " In total,  389  authors/ nodes.\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary of module (key) and authors (value)\n",
    "\n",
    "modularity = {}                            # Create a new, empty dictionary\n",
    "\n",
    "for k, v in communities.items():           # Loop through the community dictionary\n",
    "    if v not in modularity:\n",
    "        modularity[v] = [k]                # Add a new key for a modularity class the code hasn't seen before\n",
    "    else:\n",
    "        modularity[v].append(k)            # Append a name to the list for a modularity class the code has already seen\n",
    "\n",
    "\n",
    "# Create counter of countries (value) for each module (key)\n",
    "\n",
    "countries = {}\n",
    "counter = 0\n",
    "for k, v in modularity.items():            # Loop through the new dictionary\n",
    "    counter = counter + len(v)\n",
    "    country_li = []\n",
    "    for i in range(0, len(v)):\n",
    "        country = nodes_df[nodes_df['full.name.of.describer'] == v[i]]['residence.country.describer'].values[0]\n",
    "        country = str.split(country, \"; \")\n",
    "        country_li = country_li + [country[0]]\n",
    "    countries[k] = Counter(country_li)\n",
    "\n",
    "print(\"\\n In total, \", counter, \" authors/ nodes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57  modules\n"
     ]
    }
   ],
   "source": [
    "# Count number of modules\n",
    "\n",
    "print(len(modularity), \" modules\")    # number of modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dataframe of module (index) and subgraph (0 column)\n",
    "\n",
    "subgraphs = [c for c in sorted(nx.connected_components(G), key=len, reverse=True)]\n",
    "\n",
    "def get_subgraph(node_name):\n",
    "    subgraph_idx = -1\n",
    "    \n",
    "    for i in range(0, len(subgraphs)):\n",
    "        if (node_name in list(subgraphs[i])):\n",
    "            subgraph_idx = i\n",
    "    \n",
    "    return subgraph_idx\n",
    "          \n",
    "community_subgraph = pd.DataFrame.from_dict({key:get_subgraph(value[0]) for (key,value) in modularity.items()}, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get number of species for each module as a dataframe\n",
    "\n",
    "N_species = {}\n",
    "\n",
    "for i, sg in enumerate(modularity.items()):\n",
    "    spp_li = []\n",
    "    \n",
    "    for auth in sg[1]:\n",
    "        spp_li = spp_li + list(spp[spp['full.name.of.describer']==auth]['idx'].values)\n",
    "        \n",
    "    N_species[i] = len(set(spp_li))\n",
    "    \n",
    "N_species = pd.DataFrame.from_dict(N_species, orient=\"index\")\n",
    "N_species.columns = [\"N_species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary countries to pandas.DataFrame countries_df\n",
    "countries_df = pd.DataFrame.from_dict(countries, orient='index')\n",
    "cols = list(countries_df.columns.values) \n",
    "\n",
    "# Shift column [unknown] to end\n",
    "cols.pop(cols.index('[unknown]'))\n",
    "cols_rearranged = cols + ['[unknown]']\n",
    "countries_df = countries_df[cols_rearranged]\n",
    "\n",
    "# Sort by index\n",
    "countries_df = countries_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of authors and countries as a dataframe for each module\n",
    "\n",
    "countries_summary1 = countries_df.sum(axis=1)   # count number of authors in each module\n",
    "countries_summary2 = countries_df.count(axis=1) # count number of countries in each module\n",
    "\n",
    "# Combine all dataframes (N authors, N countries, Subgraph, N species)\n",
    "\n",
    "countries_summary = pd.concat([countries_summary1, countries_summary2], axis=1) \n",
    "countries_summary = countries_summary.merge(community_subgraph, \"outer\", left_index=True, right_index=True)\n",
    "countries_summary = countries_summary.merge(N_species, \"outer\", left_index=True, right_index=True)\n",
    "countries_summary.columns = ['N_authors', 'N_countries', 'Subgraph_id', 'N_species']\n",
    "countries_summary.index.names = ['Modules']\n",
    "\n",
    "# Create a new column called \"idx\" (which will be the way the dataframe is sorted later for labels)\n",
    "\n",
    "# It is sorted by Subgraph_id and N_authors\n",
    "countries_summary = countries_summary.sort_values(['Subgraph_id', 'N_authors'], ascending=[True,  False])\n",
    "countries_summary['idx'] = range(0, len(countries_summary))\n",
    "# Create label\n",
    "countries['lab'] = ' [' + countries_summary['N_authors'].astype(int).astype(str) + ',' +\\\n",
    "    countries_summary['N_countries'].astype(int).astype(str) + \",\" +\\\n",
    "    countries_summary['N_species'].astype(int).astype(str) + '] ' +\\\n",
    "    \"id\" + countries_summary.idx.astype(str).str.pad(2, \"left\", \"0\") + \" / \" +\\\n",
    "    \"S\" + countries_summary['Subgraph_id'].astype(str).str.pad(2, \"left\", \"0\")\n",
    "\n",
    "# Sort by index and save idx\n",
    "countries_summary = countries_summary.sort_index()\n",
    "idx = countries_summary.idx.values\n",
    "countries_summary = countries_summary.sort_values('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_authors</th>\n",
       "      <th>N_countries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>49.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        N_authors  N_countries\n",
       "median        2.0          1.0\n",
       "min           2.0          1.0\n",
       "max          49.0         12.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary stats for ALL subgraphs\n",
    "countries_summary.agg({\n",
    "    'N_authors': ['median', 'min', 'max'],\n",
    "    'N_countries': ['median', 'min', 'max']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N_authors    median    16.0\n",
       "             min        5.0\n",
       "             max       49.0\n",
       "N_countries  median     5.0\n",
       "             min        1.0\n",
       "             max       12.0\n",
       "             count     13.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary stats for subgraph 1\n",
    "countries_summary.groupby('Subgraph_id')\\\n",
    "                 .agg({'N_authors': ['median', 'min', 'max'],\n",
    "                       'N_countries': ['median', 'min', 'max', 'count']})\\\n",
    "                 .iloc[0] # for subgraph 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the subgraphs only have one cluster, but the largest one has 12 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get proportions\n",
    "countries_prop = countries_df.apply(lambda r: round(r/r.sum()*100, 1), axis=1)\n",
    "countries_prop.index = idx\n",
    "countries_prop = countries_prop.sort_index()\n",
    "countries_prop.index = countries['lab']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full country name from abbreviated form\n",
    "def parse_countries(country):\n",
    "    if country == \"[unknown]\":\n",
    "        return country\n",
    "    else:\n",
    "        return statoids[country]\n",
    "\n",
    "countries_prop.columns = [parse_countries(x) for x in countries_prop.columns]\n",
    "# countries_prop.columns = countries_prop.columns + \" [\" + countries_prop.count().astype(str) + \"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Algeria', 'Austria', 'Gambia', 'Germany', 'Israel', 'Japan',\n",
       "       'Netherlands', 'Russian Federation', 'Turkey', 'Argentina', 'Chile',\n",
       "       'Spain', 'United States of America', 'Australia', 'Belgium', 'Canada',\n",
       "       'Cameroon', 'Ethiopia', 'France', 'New Zealand', 'South Africa',\n",
       "       'Thailand', 'China', 'Indonesia', 'Norway', 'Sweden', 'Taiwan',\n",
       "       'Brazil', 'Colombia', 'Denmark', 'Czech Republic', 'Mexico', 'Peru',\n",
       "       'Saudi Arabia', 'United Kingdom', 'Costa Rica', 'India', 'Pakistan',\n",
       "       'Panama', 'Italy', 'Switzerland', 'Paraguay', 'Cuba', 'Kenya',\n",
       "       'Portugal', 'Ukraine', 'Iran', 'Korea, South', 'Venezuela',\n",
       "       '[unknown]'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_prop.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graph\n",
    "countries_prop_t = countries_prop.transpose(copy=True)\n",
    "countries_prop_t[countries_prop_t.columns] = countries_prop_t[countries_prop_t.columns].replace({0: float('nan')})\n",
    "plt.figure(figsize=(15, 13))\n",
    "ax = sns.heatmap(countries_prop_t, cmap=plt.get_cmap(\"Spectral_r\"), linecolor=\"k\", linewidths=0.1)\n",
    "ax.set(xlabel='\\nProportion of country from each module (%)', ylabel='Countries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_prop.iloc[3][countries_prop.iloc[3].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate diversity indices\n",
    "\n",
    "indices_simpsons = []\n",
    "indices_shannon = []\n",
    "\n",
    "for i, idx in enumerate(countries_prop.index):\n",
    "    country_counts = [x for x in countries_prop.iloc[i].values if not math.isnan(x)]\n",
    "    \n",
    "    # indices = countries_prop.iloc[i][countries_prop.iloc[i].notna()].values\n",
    "    indices_simpsons =  indices_simpsons + [b.simpson(country_counts)]\n",
    "    indices_shannon =  indices_shannon + [b.shannon(country_counts)]\n",
    "\n",
    "countries_summary['simpson'] = indices_simpsons\n",
    "countries_summary['shannon'] = indices_shannon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_summary_original = countries_summary.copy(deep=True)\n",
    "countries_summary_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countries_summary = countries_summary_original.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale values by min max for PCA\n",
    "\n",
    "cols = ['N_authors', 'N_countries', 'N_species', 'simpson']\n",
    "x = countries_summary[cols].values #returns a numpy array\n",
    "scaler = preprocessing.StandardScaler()\n",
    "countries_summary_scaled = pd.DataFrame(scaler.fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "\n",
    "pca = PCA(n_components=2, svd_solver='full')\n",
    "pca.fit(countries_summary_scaled)\n",
    "pca.values = pca.transform(countries_summary_scaled)\n",
    "pca.values = pd.DataFrame(pca.values, columns=['PC1', 'PC2'])\n",
    "\n",
    "var = pca.explained_variance_ratio_\n",
    "countries_summary = countries_summary.reset_index().merge(pca.values, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform DBSCAN\n",
    "cluster = KMeans(n_clusters=5, random_state=22).fit(countries_summary[['PC1', 'PC2']].values)\n",
    "countries_summary['KMeans group'] = cluster.labels_ + 1\n",
    "countries_summary.loc[countries_summary['KMeans group'] == 0, 'KMeans group'] = \"Ungrouped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the PCA components (loadings)\n",
    "PCs = pca.components_\n",
    "\n",
    "# Use quiver to generate the basic plot\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "plt.quiver(np.zeros(PCs.shape[1]), np.zeros(PCs.shape[1]),\n",
    "           PCs[0,:]*4, PCs[1,:]*3, \n",
    "           angles='xy', scale_units='xy', scale=1, \n",
    "           width = 0.001, headwidth = 20, headlength = 20)\n",
    "\n",
    "# Add labels based on feature names (here just numbers)\n",
    "feature_names = ['N authors', 'N countries', 'N species', 'Simpsons']\n",
    "for i,j,z in zip(PCs[1,:]*2, PCs[0,:]*3, feature_names):\n",
    "    plt.text(j, i, z, ha='center', va='center')\n",
    "\n",
    "# # Add unit circle\n",
    "# circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')\n",
    "# plt.gca().add_artist(circle)\n",
    "\n",
    "# Ensure correct aspect ratio and axis limits\n",
    "# plt.axis('equal')\n",
    "plt.xlim([countries_summary['PC1'].min()-1, countries_summary['PC1'].max()+1])\n",
    "plt.ylim([countries_summary['PC2'].min()-1, countries_summary['PC2'].max()+1])\n",
    "\n",
    "# Plot value\n",
    "n_colours = len(countries_summary['KMeans group'].unique())\n",
    "sns.scatterplot(countries_summary['PC1'], countries_summary['PC2'],  \n",
    "                hue=countries_summary['KMeans group'], palette=sns.color_palette(\"hls\", n_colours), legend=\"brief\")\n",
    "\n",
    "# Label axes\n",
    "xlab = \"PC 1 [\" + str(round(var[0]*100, 1)) + \"%]\"\n",
    "plt.xlabel(xlab)\n",
    "ylab = \"PC 2 [\" + str(round(var[1]*100, 1)) + \"%]\"\n",
    "plt.ylabel(ylab)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_summary.agg({'N_authors': ['count', 'median', 'min', 'max'],\n",
    "                       'N_countries': ['median', 'min', 'max'],\n",
    "                       'N_species': ['median', 'min', 'max'],\n",
    "                       'simpson': ['median', 'min', 'max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary stats for subgraph 1\n",
    "countries_summary.groupby('KMeans group')\\\n",
    "                 .agg({'N_authors': ['count', 'median', 'min', 'max'],\n",
    "                       'N_countries': ['median', 'min', 'max'],\n",
    "                       'N_species': ['median', 'min', 'max'],\n",
    "                       'simpson': ['median', 'min', 'max']})\n",
    "\n",
    "# group 1: high authors, low countries, high species, low simpsons = not international, contribute to many species\n",
    "# group 2: mid authors, mid countries, mid species, high simpsons = international, mid-sized\n",
    "# group 3: low authors, low countries, low species, mid simpsons = international, small-sized\n",
    "# group 4: high authors, high countries, high species, high simpsons = international, big-sized\n",
    "# group 5: low authors, low countries, low species, low simpsons = not international, contribute to few species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_summary.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraphs_subset = countries_summary[(countries_summary.N_countries>=3) & (countries_summary.Subgraph_id==0)]\n",
    "\n",
    "spp_li = []\n",
    "counter = 0\n",
    "for i, sg in enumerate(subgraphs_subset.index.values):\n",
    "    for auth in modularity[sg]:\n",
    "        spp_li = spp_li + list(spp[spp['full.name.of.describer']==auth]['idx'].values)\n",
    "    counter += 1\n",
    "\n",
    "spp_li = len(set(spp_li))\n",
    "n_auth = subgraphs_subset['N_authors'].sum()\n",
    "from_subgraphs = subgraphs_subset['Subgraph_id'].unique()\n",
    "\n",
    "print(\n",
    "    \"Authors with >=3 countries accounted for\", spp_li, \"species for \", counter, \" clusters/modules and with\", \n",
    "    n_auth, \"authors from subgraphs\", from_subgraphs, \"( n=\", len(from_subgraphs), \").\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusters with only 2 countries\n",
    "print(len(countries_summary[countries_summary.N_countries==2]))\n",
    "# Clusters with only 1 country\n",
    "print(len(countries_summary[countries_summary.N_countries==1]))\n",
    "# Clusters with only 1 country and 2 authors\n",
    "print(len(countries_summary[(countries_summary.N_countries==1) & (countries_summary.N_authors <=2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(countries_summary[countries_summary['KMeans group']==1], \"\\n\")\n",
    "\n",
    "# Brazil group and US/New Zealand group (\"old\")\n",
    "print(modularity[9], \"\\n\")\n",
    "print(modularity[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "countries_df_m2 = countries_df.loc[countries_df.count(axis=1) > 2] # countries with <=2\n",
    "print(countries_df_m2.count(axis=0).sort_values(ascending=False)[0:10])\n",
    "\n",
    "countries_df_l2 = countries_df.loc[countries_df.count(axis=1) < 2] # countries with <=2\n",
    "print(countries_df_l2.count(axis=0).sort_values(ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_summary.sort_values('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "ax = sns.regplot(countries_summary['N_countries'], countries_summary['N_authors'])\n",
    "ax.set(xlabel='\\n Number of countries', \n",
    "       ylabel='Number of authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "[get_highest_eigen_in_module(x) for x in countries_summary[countries_summary.N_authors>=10].index.values]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
